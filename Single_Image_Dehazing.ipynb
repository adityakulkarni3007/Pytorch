{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJPU0tPrAAAi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import glob\n",
    "import torch\n",
    "import scipy\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.utils import data\n",
    "from sklearn import datasets\n",
    "from skimage.io import imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F3\n",
    "import torch.nn.functional as F9\n",
    "from sklearn import linear_model\n",
    "from skimage.feature import canny\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt1\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import display, Image\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms.functional as F6\n",
    "import torchvision.transforms.functional as F7\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3OcaGLs7bOiE"
   },
   "source": [
    "Defining our generator (UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPQd3FlmAAAk"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=3, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(\n",
    "            in_channels=128, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "        self.pyramid_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=5, padding=2),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=7, padding=3),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_11 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=11, padding=5),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_17 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=17, padding=8),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_25 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=25, padding=12),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_35 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=35, padding=17),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.pyramid_45 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=16, kernel_size=45, padding=22),\n",
    "            nn.InstanceNorm2d(16, track_running_stats=False),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #block1\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        coonv1_1 = self.conv(dec1)\n",
    "\n",
    "        \n",
    "        #block2 \n",
    "        enc1_2 = self.encoder1(coonv1_1)\n",
    "        enc2_2 = self.encoder2(self.pool1(enc1_2))\n",
    "        enc3_2 = self.encoder3(self.pool2(enc2_2))\n",
    "        enc4_2 = self.encoder4(self.pool3(enc3_2))\n",
    "\n",
    "        bottleneck_2 = self.bottleneck(self.pool4(enc4_2))\n",
    "\n",
    "        dec4_2 = self.upconv4(bottleneck_2)\n",
    "        dec4_2 = torch.cat((dec4_2, enc4_2), dim=1)\n",
    "        dec4_2 = self.decoder4(dec4_2)\n",
    "        dec3_2 = self.upconv3(dec4_2)\n",
    "        dec3_2 = torch.cat((dec3_2, enc3_2), dim=1)\n",
    "        dec3_2 = self.decoder3(dec3_2)\n",
    "        dec2_2 = self.upconv2(dec3_2)\n",
    "        dec2_2 = torch.cat((dec2_2, enc2_2), dim=1)\n",
    "        dec2_2 = self.decoder2(dec2_2)\n",
    "        dec1_2 = self.upconv1(dec2_2)\n",
    "        dec1_2 = torch.cat((dec1_2, enc1_2), dim=1)\n",
    "        dec1_2 = self.decoder1(dec1_2)\n",
    "        coonv1_2 = self.conv(dec1_2)\n",
    "\n",
    "\n",
    "        \n",
    "        #block3\n",
    "        enc1_3 = self.encoder1(coonv1_2)\n",
    "        enc2_3 = self.encoder2(self.pool1(enc1_3))\n",
    "        enc3_3 = self.encoder3(self.pool2(enc2_3))\n",
    "        enc4_3 = self.encoder4(self.pool3(enc3_3))\n",
    "\n",
    "        bottleneck_3 = self.bottleneck(self.pool4(enc4_3))\n",
    "\n",
    "        dec4_3 = self.upconv4(bottleneck_3)\n",
    "        dec4_3 = torch.cat((dec4_3, enc4_3), dim=1)\n",
    "        dec4_3 = self.decoder4(dec4_3)\n",
    "        dec3_3 = self.upconv3(dec4_3)\n",
    "        dec3_3 = torch.cat((dec3_3, enc3_3), dim=1)\n",
    "        dec3_3 = self.decoder3(dec3_3)\n",
    "        dec2_3 = self.upconv2(dec3_3)\n",
    "        dec2_3 = torch.cat((dec2_3, enc2_3), dim=1)\n",
    "        dec2_3 = self.decoder2(dec2_3)\n",
    "        dec1_3 = self.upconv1(dec2_3)\n",
    "        dec1_3 = torch.cat((dec1_3, enc1_3), dim=1)\n",
    "        dec1_3 = self.decoder1(dec1_3)\n",
    "        coonv1_3 = self.conv(dec1_3)\n",
    "\n",
    "\n",
    "        #block4\n",
    "        enc1_4 = self.encoder1(coonv1_3)\n",
    "        enc2_4 = self.encoder2(self.pool1(enc1_4))\n",
    "        enc3_4 = self.encoder3(self.pool2(enc2_4))\n",
    "        enc4_4 = self.encoder4(self.pool3(enc3_4))\n",
    "\n",
    "        bottleneck_4 = self.bottleneck(self.pool4(enc4_4))\n",
    "\n",
    "        dec4_4 = self.upconv4(bottleneck_4)\n",
    "        dec4_4 = torch.cat((dec4_4, enc4_4), dim=1)\n",
    "        dec4_4 = self.decoder4(dec4_4)\n",
    "        dec3_4 = self.upconv3(dec4_4)\n",
    "        dec3_4 = torch.cat((dec3_4, enc3_4), dim=1)\n",
    "        dec3_4 = self.decoder3(dec3_4)\n",
    "        dec2_4 = self.upconv2(dec3_4)\n",
    "        dec2_4 = torch.cat((dec2_4, enc2_4), dim=1)\n",
    "        dec2_4 = self.decoder2(dec2_4)\n",
    "        dec1_4 = self.upconv1(dec2_4)\n",
    "        dec1_4 = torch.cat((dec1_4, enc1_4), dim=1)\n",
    "        dec1_4 = self.decoder1(dec1_4)\n",
    "        coonv1_4 = self.conv(dec1_4)\n",
    "\n",
    "        #concatenation of different UNet feature maps\n",
    "        concat = torch.cat((coonv1_1, coonv1_2, coonv1_3, coonv1_4  ), dim=1)\n",
    "\n",
    "\n",
    "        #pyramid convolution\n",
    "        conv_pyramid_3 =  self.pyramid_3(concat)\n",
    "        conv_pyramid_5 =  self.pyramid_5(concat)\n",
    "        conv_pyramid_7 =  self.pyramid_7(concat)\n",
    "        conv_pyramid_11 =  self.pyramid_11(concat)\n",
    "        conv_pyramid_17 =  self.pyramid_17(concat)\n",
    "        conv_pyramid_25 =  self.pyramid_25(concat)\n",
    "        conv_pyramid_35 =  self.pyramid_35(concat)\n",
    "        conv_pyramid_45 =  self.pyramid_45(concat)\n",
    "\n",
    "        #concatenation of feature maps corresponding different convolution filters present in Pyramid convolution layer\n",
    "        concat_py = torch.cat(( conv_pyramid_3, conv_pyramid_5, conv_pyramid_7, conv_pyramid_11, conv_pyramid_17, conv_pyramid_25, conv_pyramid_35, conv_pyramid_45), dim=1)\n",
    "      \n",
    "        return torch.sigmoid(self.conv_1(concat_py))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzLeMds8bglC"
   },
   "source": [
    "Defining our Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zk5I8Q_mAAAm"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True):\n",
    "        super().__init__()\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "        self.conv1 = self.features = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        outputs = conv5\n",
    "        if self.use_sigmoid:\n",
    "            outputs = torch.sigmoid(conv5)\n",
    "\n",
    "        return outputs, [conv1, conv2, conv3, conv4, conv5]\n",
    "\n",
    "def spectral_norm(module, mode=True):\n",
    "    if mode:\n",
    "        return nn.utils.spectral_norm(module)\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqRl8shQbkm_"
   },
   "source": [
    "Defining our loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0FLH3Z9lAAAo"
   },
   "outputs": [],
   "source": [
    "class AdversarialLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "    Adversarial loss\n",
    "    https://arxiv.org/abs/1711.10337\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, type='hinge', target_real_label=1.0, target_fake_label=0.0):\n",
    "        r\"\"\"\n",
    "        type = nsgan | lsgan | hinge\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.type = type\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "\n",
    "        if type == 'nsgan':\n",
    "            self.criterion = nn.BCELoss()\n",
    "\n",
    "        elif type == 'lsgan':\n",
    "            self.criterion = nn.MSELoss()\n",
    "\n",
    "        elif type == 'hinge':\n",
    "            self.criterion = nn.ReLU()\n",
    "\n",
    "    def __call__(self, outputs, is_real, is_disc=None):\n",
    "        if self.type == 'hinge':\n",
    "            if is_real:\n",
    "              return -torch.log(outputs).mean()\n",
    "            else:\n",
    "              return -torch.log(1-outputs).mean()\n",
    "\n",
    "\n",
    "        else:\n",
    "            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            return loss\n",
    "\n",
    "\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "    Perceptual loss, VGG-based\n",
    "    https://arxiv.org/abs/1603.08155\n",
    "    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n",
    "        super().__init__()\n",
    "        self.add_module('vgg', VGG19().cuda())\n",
    "        self.criterion = torch.nn.L1Loss().cuda()\n",
    "        self.weights = weights\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        # Compute features\n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "\n",
    "        content_loss = 0.0\n",
    "        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n",
    "        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n",
    "        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n",
    "        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n",
    "        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n",
    "\n",
    "\n",
    "        return content_loss\n",
    "\n",
    "\n",
    "\n",
    "class VGG19(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        features = models.vgg19(pretrained=True).features\n",
    "        self.relu1_1 = torch.nn.Sequential()\n",
    "        self.relu1_2 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu2_1 = torch.nn.Sequential()\n",
    "        self.relu2_2 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu3_1 = torch.nn.Sequential()\n",
    "        self.relu3_2 = torch.nn.Sequential()\n",
    "        self.relu3_3 = torch.nn.Sequential()\n",
    "        self.relu3_4 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu4_1 = torch.nn.Sequential()\n",
    "        self.relu4_2 = torch.nn.Sequential()\n",
    "        self.relu4_3 = torch.nn.Sequential()\n",
    "        self.relu4_4 = torch.nn.Sequential()\n",
    "\n",
    "        self.relu5_1 = torch.nn.Sequential()\n",
    "        self.relu5_2 = torch.nn.Sequential()\n",
    "        self.relu5_3 = torch.nn.Sequential()\n",
    "        self.relu5_4 = torch.nn.Sequential()\n",
    "\n",
    "        for x in range(2):\n",
    "            self.relu1_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(2, 4):\n",
    "            self.relu1_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(4, 7):\n",
    "            self.relu2_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(7, 9):\n",
    "            self.relu2_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(9, 12):\n",
    "            self.relu3_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(12, 14):\n",
    "            self.relu3_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(14, 16):\n",
    "            self.relu3_3.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(16, 18):\n",
    "            self.relu3_4.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(18, 21):\n",
    "            self.relu4_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(21, 23):\n",
    "            self.relu4_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(23, 25):\n",
    "            self.relu4_3.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(25, 27):\n",
    "            self.relu4_4.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(27, 30):\n",
    "            self.relu5_1.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(30, 32):\n",
    "            self.relu5_2.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(32, 34):\n",
    "            self.relu5_3.add_module(str(x), features[x])\n",
    "\n",
    "        for x in range(34, 36):\n",
    "            self.relu5_4.add_module(str(x), features[x])\n",
    "\n",
    "        # don't need the gradients, just want the features\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        relu1_1 = self.relu1_1(x)\n",
    "        relu1_2 = self.relu1_2(relu1_1)\n",
    "\n",
    "        relu2_1 = self.relu2_1(relu1_2)\n",
    "        relu2_2 = self.relu2_2(relu2_1)\n",
    "\n",
    "        relu3_1 = self.relu3_1(relu2_2)\n",
    "        relu3_2 = self.relu3_2(relu3_1)\n",
    "        relu3_3 = self.relu3_3(relu3_2)\n",
    "        relu3_4 = self.relu3_4(relu3_3)\n",
    "\n",
    "        relu4_1 = self.relu4_1(relu3_4)\n",
    "        relu4_2 = self.relu4_2(relu4_1)\n",
    "        relu4_3 = self.relu4_3(relu4_2)\n",
    "        relu4_4 = self.relu4_4(relu4_3)\n",
    "\n",
    "        relu5_1 = self.relu5_1(relu4_4)\n",
    "        relu5_2 = self.relu5_2(relu5_1)\n",
    "        relu5_3 = self.relu5_3(relu5_2)\n",
    "        relu5_4 = self.relu5_4(relu5_3)\n",
    "\n",
    "        out = {\n",
    "            'relu1_1': relu1_1,\n",
    "            'relu1_2': relu1_2,\n",
    "\n",
    "            'relu2_1': relu2_1,\n",
    "            'relu2_2': relu2_2,\n",
    "\n",
    "            'relu3_1': relu3_1,\n",
    "            'relu3_2': relu3_2,\n",
    "            'relu3_3': relu3_3,\n",
    "            'relu3_4': relu3_4,\n",
    "\n",
    "            'relu4_1': relu4_1,\n",
    "            'relu4_2': relu4_2,\n",
    "            'relu4_3': relu4_3,\n",
    "            'relu4_4': relu4_4,\n",
    "\n",
    "            'relu5_1': relu5_1,\n",
    "            'relu5_2': relu5_2,\n",
    "            'relu5_3': relu5_3,\n",
    "            'relu5_4': relu5_4,\n",
    "        }\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCVcqVjAAAAr"
   },
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F3.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F3.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F3.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F3.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F3.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtvXXCtxboWU"
   },
   "source": [
    "Defining our model i.e. DU_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNTpEUunAAAw"
   },
   "outputs": [],
   "source": [
    "class DU_Net(nn.Module):\n",
    "\n",
    "    def __init__(self, unet_input, unet_output, discriminator_input):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        unet = UNet(in_channels=unet_input ,out_channels=unet_output)\n",
    "        unet = nn.DataParallel(unet, device_ids=[0])\n",
    "        unet = unet.cuda()\n",
    "\n",
    "        discriminator = Discriminator(in_channels=discriminator_input , use_sigmoid=True)\n",
    "        discriminator = nn.DataParallel(discriminator, device_ids=[0])\n",
    "        discriminator = discriminator.cuda()\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        adversarial_loss = AdversarialLoss(type='hinge')\n",
    "        l1_loss = nn.L1Loss()\n",
    "        content_loss = ContentLoss()\n",
    "        ssim = SSIM(window_size = 11)\n",
    "        bce = nn.BCELoss()\n",
    "\n",
    "        self.add_module('unet', unet)\n",
    "        self.add_module('discriminator', discriminator)\n",
    "\n",
    "        self.add_module('criterion', criterion)\n",
    "        self.add_module('adversarial_loss', adversarial_loss)\n",
    "        self.add_module('l1_loss', l1_loss)\n",
    "        self.add_module('content_loss', content_loss)\n",
    "        self.add_module('ssim_loss', ssim)\n",
    "        self.add_module('bce_loss', bce)\n",
    "        \n",
    "\n",
    "        self.unet_optimizer = optim.Adam(\n",
    "            unet.parameters(), \n",
    "            lr = float(0.00001),\n",
    "            betas=(0.9, 0.999)\n",
    "            )\n",
    "\n",
    "        self.dis_optimizer = optim.Adam(\n",
    "             params=discriminator.parameters(),\n",
    "             lr=float(0.00001),\n",
    "             betas=(0.9, 0.999)\n",
    "             )\n",
    "\n",
    "        self.unet_input = unet_input\n",
    "        self.unet_output = unet_output\n",
    "        self.discriminator_input = discriminator_input\n",
    "\n",
    "\n",
    "    def load(self, path_unet, path_discriminator):\n",
    "        weight_unet = torch.load(path_unet)\n",
    "        weight_discriminator = torch.load(path_discriminator)\n",
    "        self.unet.load_state_dict(weight_unet)\n",
    "        self.discriminator.load_state_dict(weight_discriminator)\n",
    "\n",
    "    def save_weight(self, path_unet, path_dis):\n",
    "        torch.save(self.unet.state_dict(), path_unet)\n",
    "        torch.save(self.discriminator.state_dict(), path_dis)\n",
    "\n",
    "    def process(self, haze_images, dehaze_images):\n",
    "\n",
    "        # zero optimizers\n",
    "        self.unet_optimizer.zero_grad(set_to_none=True)\n",
    "        self.dis_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "\n",
    "        # find output and initialize loss to zero\n",
    "        unet_loss = 0\n",
    "        dis_loss = 0\n",
    "\n",
    "        outputs = self.unet(haze_images.cuda())\n",
    "\n",
    "\n",
    "        # discriminator loss\n",
    "        dis_real, dis_real_feat = self.discriminator(dehaze_images.cuda())        \n",
    "        dis_fake, dis_fake_feat = self.discriminator(outputs.detach().cuda())       \n",
    "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
    "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
    "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
    "\n",
    "\n",
    "        # unet loss\n",
    "        unet_fake, unet_fake_feat = self.discriminator(outputs.cuda())        \n",
    "        unet_gan_loss = self.adversarial_loss(unet_fake, True, False) * 0.7\n",
    "        unet_loss += unet_gan_loss\n",
    "\n",
    "        unet_criterion = self.criterion(outputs.cuda(), dehaze_images.cuda())\n",
    "        unet_loss += unet_criterion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        gen_content_loss = self.content_loss(outputs.cuda(), dehaze_images.cuda())\n",
    "        gen_content_loss = (gen_content_loss * 0.7).cuda()\n",
    "        unet_loss += gen_content_loss.cuda()\n",
    "        \n",
    "        \n",
    "        ssim_loss =  self.ssim_loss(outputs.cuda(), dehaze_images.cuda())\n",
    "        ssim_loss = (1-ssim_loss)*2\n",
    "        unet_loss += ssim_loss.cuda()\n",
    "\n",
    "        return unet_loss, ssim_loss, unet_criterion, 1-ssim_loss/2\n",
    "\n",
    "    def backward(self, unet_loss, dis_loss):\n",
    "        dis_loss.backward(retain_graph = True)\n",
    "        self.dis_optimizer.step()\n",
    "\n",
    "        unet_loss.backward()\n",
    "        self.unet_optimizer.step()\n",
    "        \n",
    "\n",
    "    def predict(self, haze_images):\n",
    "      predict_mask = self.unet(haze_images.cuda())\n",
    "      return predict_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5NG1aLzbtmE"
   },
   "source": [
    "Defining our and creating the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4Zt47MJAAA0"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, haze_list, dehaze_list, augment=False):\n",
    "        super().__init__()\n",
    "        self.augment = augment\n",
    "        self.haze_list = haze_list\n",
    "        self.dehaze_list = dehaze_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 210\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            item = self.load_item(index)\n",
    "        except:\n",
    "            print('loading error: ' + self.haze_list[index])\n",
    "            item = self.load_item(0)\n",
    "            \n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "    def load_item(self, index):\n",
    "        val = 1024*2           #crop size i.e hight and width\n",
    "        size_data = 25         #depends on the no. of training images in the dataset\n",
    "        height_data = 4657     #heigth of the training images\n",
    "        width_data = 2833      #width of the training images\n",
    "\n",
    "        numx = random.randint(0, height_data-val)\n",
    "        numy = random.randint(0, width_data-val)\n",
    "\n",
    "        haze_image = cv2.imread(self.haze_list[index%size_data])\n",
    "        dehaze_image = cv2.imread(self.dehaze_list[index%size_data])\n",
    "        haze_image = PIL.Image.fromarray(haze_image)\n",
    "        dehaze_image = PIL.Image.fromarray(dehaze_image)\n",
    "\n",
    "        haze_crop=haze_image.crop((numx, numy, numx+val, numy+val))\n",
    "        dehaze_crop=dehaze_image.crop((numx, numy, numx+val, numy+val))\n",
    " \n",
    "        haze_crop = haze_crop.resize((512,512), resample=PIL.Image.BICUBIC)\n",
    "        dehaze_crop = dehaze_crop.resize((512,512), resample=PIL.Image.BICUBIC)\n",
    "\n",
    "        haze_crop = np.array(haze_crop)\n",
    "        dehaze_crop = np.array(dehaze_crop)\n",
    "        haze_crop = cv2.cvtColor(haze_crop, cv2.COLOR_BGR2YCrCb)\n",
    "        dehaze_crop = cv2.cvtColor(dehaze_crop, cv2.COLOR_BGR2YCrCb)\n",
    "        haze_crop = self.to_tensor(haze_crop).cuda()\n",
    "        dehaze_crop = self.to_tensor(dehaze_crop).cuda()\n",
    "        \n",
    "        return haze_crop.cuda(), dehaze_crop.cuda()\n",
    "    \n",
    "    def to_tensor(self, img):\n",
    "        img_t = F.to_tensor(img).float()\n",
    "        return img_t\n",
    "\n",
    "\n",
    "    def create_iterator(self, batch_size):\n",
    "        while True:\n",
    "            sample_loader = DataLoader(\n",
    "                dataset=self,\n",
    "                batch_size=batch_size,\n",
    "                drop_last=True\n",
    "            )\n",
    "\n",
    "            for item in sample_loader:\n",
    "                yield item\n",
    "\n",
    "\n",
    "path_of_train_hazy_images = 'train/haze/*.jpg'\n",
    "path_of_train_gt_images = 'train/gt/*.jpg'\n",
    "\n",
    "images_paths_train_gt=glob.glob(path_of_train_gt_images)\n",
    "image_paths_train_hazy=glob.glob(path_of_train_hazy_images)\n",
    "\n",
    "train_dataset = Dataset(image_paths_train_hazy, images_paths_train_gt, augment=False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=0,\n",
    "            drop_last=True,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQW0X3g5dNBX"
   },
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZACwe8ObAABE"
   },
   "outputs": [],
   "source": [
    "graph_gloss = []\n",
    "input_unet_channel = 3\n",
    "output_unet_channel = 3\n",
    "input_dis_channel = 3\n",
    "max_epochs = 100\n",
    "DUNet = DU_Net(input_unet_channel ,output_unet_channel ,input_dis_channel).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gb7PvZASdQn1"
   },
   "source": [
    "Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24-9evbnAABM"
   },
   "outputs": [],
   "source": [
    "def train(max_epochs):\n",
    "    for epoch in range(max_epochs):\n",
    "        i=1\n",
    "        mse_epoch = 0.0\n",
    "        ssim_epoch = 0.0\n",
    "        unet_epoch = 0.0\n",
    "        for haze_images, dehaze_images, in train_loader:\n",
    "            unet_loss, dis_loss, mse, ssim = DUNet.process(haze_images.cuda(), dehaze_images.cuda())\n",
    "            DUNet.backward(unet_loss.cuda(), dis_loss.cuda())\n",
    "            print('Epoch: '+str(epoch+1)+ ' || Batch: '+str(i)+ \" || unet loss: \"+str(unet_loss.cpu().item()) + \" || dis loss: \"+str(dis_loss.cpu().item()) + \" || mse: \"+str(mse.cpu().item()) + \" | ssim:\" + str(ssim.cpu().item()) )\n",
    "            mse_epoch =  mse_epoch + mse.cpu().item() \n",
    "            ssim_epoch = ssim_epoch + ssim.cpu().item()\n",
    "            unet_epoch = unet_epoch + unet_loss.cpu().item()\n",
    "            i=i+1\n",
    "        \n",
    "        print()\n",
    "        mse_epoch = mse_epoch/i\n",
    "        ssim_epoch = ssim_epoch/i\n",
    "        unet_epoch = unet_epoch/i\n",
    "        graph_gloss.append(ssim_epoch)\n",
    "        print(\"mse: + \"+str(mse_epoch) + \" | ssim: \"+ str(ssim_epoch)+ \" | unet:\"+str(unet_epoch))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29CCGgMDdTPe"
   },
   "source": [
    "Calling training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmEpSm9jAABP",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "870910645 || mse: 0.0008236855501309037 | ssim:0.9431957006454468\n",
      "Epoch: 150 || Batch: 75 || unet loss: 1.0809705257415771 || dis loss: 0.15170812606811523 || mse: 0.0013822871260344982 | ssim:0.9241459369659424\n",
      "Epoch: 150 || Batch: 76 || unet loss: 0.8387935161590576 || dis loss: 0.16976559162139893 || mse: 0.001342686591669917 | ssim:0.9151172041893005\n",
      "Epoch: 150 || Batch: 77 || unet loss: 0.8834663033485413 || dis loss: 0.11398172378540039 || mse: 0.001140528591349721 | ssim:0.9430091381072998\n",
      "Epoch: 150 || Batch: 78 || unet loss: 0.7954857349395752 || dis loss: 0.06030905246734619 || mse: 0.0018104608170688152 | ssim:0.9698454737663269\n",
      "Epoch: 150 || Batch: 79 || unet loss: 0.8483772277832031 || dis loss: 0.09848999977111816 || mse: 0.0006209785351529717 | ssim:0.9507550001144409\n",
      "Epoch: 150 || Batch: 80 || unet loss: 1.1179182529449463 || dis loss: 0.1636056900024414 || mse: 0.0008841330418363214 | ssim:0.9181971549987793\n",
      "Epoch: 150 || Batch: 81 || unet loss: 0.9858085513114929 || dis loss: 0.13449668884277344 || mse: 0.0009014915558509529 | ssim:0.9327516555786133\n",
      "Epoch: 150 || Batch: 82 || unet loss: 0.7526865005493164 || dis loss: 0.05853748321533203 || mse: 0.00030730775324627757 | ssim:0.970731258392334\n",
      "Epoch: 150 || Batch: 83 || unet loss: 1.059720516204834 || dis loss: 0.1363612413406372 || mse: 0.0013600920792669058 | ssim:0.9318193793296814\n",
      "Epoch: 150 || Batch: 84 || unet loss: 0.9745000600814819 || dis loss: 0.25949060916900635 || mse: 0.002673560753464699 | ssim:0.8702546954154968\n",
      "Epoch: 150 || Batch: 85 || unet loss: 0.849860429763794 || dis loss: 0.07620775699615479 || mse: 0.0018854751251637936 | ssim:0.9618961215019226\n",
      "Epoch: 150 || Batch: 86 || unet loss: 0.9363961815834045 || dis loss: 0.10253298282623291 || mse: 0.002064590808004141 | ssim:0.9487335085868835\n",
      "Epoch: 150 || Batch: 87 || unet loss: 0.9293186664581299 || dis loss: 0.1144787073135376 || mse: 0.0010566954733803868 | ssim:0.9427606463432312\n",
      "Epoch: 150 || Batch: 88 || unet loss: 0.8815014958381653 || dis loss: 0.20303499698638916 || mse: 0.002107436303049326 | ssim:0.8984825015068054\n",
      "Epoch: 150 || Batch: 89 || unet loss: 1.0245267152786255 || dis loss: 0.14252722263336182 || mse: 0.007307529449462891 | ssim:0.9287363886833191\n",
      "Epoch: 150 || Batch: 90 || unet loss: 1.1239769458770752 || dis loss: 0.1627655029296875 || mse: 0.0014063676353543997 | ssim:0.9186172485351562\n",
      "Epoch: 150 || Batch: 91 || unet loss: 1.1782736778259277 || dis loss: 0.17945098876953125 || mse: 0.0024123736657202244 | ssim:0.9102745056152344\n",
      "Epoch: 150 || Batch: 92 || unet loss: 1.147027850151062 || dis loss: 0.1974806785583496 || mse: 0.0013010898837819695 | ssim:0.9012596607208252\n",
      "Epoch: 150 || Batch: 93 || unet loss: 0.8424237966537476 || dis loss: 0.08309006690979004 || mse: 0.000456782930996269 | ssim:0.958454966545105\n",
      "Epoch: 150 || Batch: 94 || unet loss: 1.0707085132598877 || dis loss: 0.13392853736877441 || mse: 0.00202730018645525 | ssim:0.9330357313156128\n",
      "Epoch: 150 || Batch: 95 || unet loss: 1.1375057697296143 || dis loss: 0.16658413410186768 || mse: 0.001283959485590458 | ssim:0.9167079329490662\n",
      "Epoch: 150 || Batch: 96 || unet loss: 1.0366096496582031 || dis loss: 0.15045320987701416 || mse: 0.0020547157619148493 | ssim:0.9247733950614929\n",
      "Epoch: 150 || Batch: 97 || unet loss: 0.7848019599914551 || dis loss: 0.0579448938369751 || mse: 0.000688323169015348 | ssim:0.9710275530815125\n",
      "Epoch: 150 || Batch: 98 || unet loss: 0.8953166007995605 || dis loss: 0.07003378868103027 || mse: 0.00074774120002985 | ssim:0.9649831056594849\n",
      "Epoch: 150 || Batch: 99 || unet loss: 0.8899399042129517 || dis loss: 0.1119009256362915 || mse: 0.0009001086000353098 | ssim:0.9440495371818542\n",
      "Epoch: 150 || Batch: 100 || unet loss: 1.0494463443756104 || dis loss: 0.13592267036437988 || mse: 0.0013323232997208834 | ssim:0.9320386648178101\n",
      "Epoch: 150 || Batch: 101 || unet loss: 0.884599506855011 || dis loss: 0.12483692169189453 || mse: 0.0010667785536497831 | ssim:0.9375815391540527\n",
      "Epoch: 150 || Batch: 102 || unet loss: 0.9253067970275879 || dis loss: 0.23230648040771484 || mse: 0.0021506636403501034 | ssim:0.8838467597961426\n",
      "Epoch: 150 || Batch: 103 || unet loss: 0.8310081362724304 || dis loss: 0.06660747528076172 || mse: 0.001493115327320993 | ssim:0.9666962623596191\n",
      "Epoch: 150 || Batch: 104 || unet loss: 0.8786263465881348 || dis loss: 0.2341533899307251 || mse: 0.002250445308163762 | ssim:0.8829233050346375\n",
      "Epoch: 150 || Batch: 105 || unet loss: 1.033193588256836 || dis loss: 0.1266157627105713 || mse: 0.0008240969618782401 | ssim:0.9366921186447144\n",
      "Epoch: 150 || Batch: 106 || unet loss: 0.8601200580596924 || dis loss: 0.10485959053039551 || mse: 0.001405228627845645 | ssim:0.9475702047348022\n",
      "Epoch: 150 || Batch: 107 || unet loss: 0.7647730708122253 || dis loss: 0.06171989440917969 || mse: 0.0003411079233046621 | ssim:0.9691400527954102\n",
      "Epoch: 150 || Batch: 108 || unet loss: 1.118754506111145 || dis loss: 0.15932941436767578 || mse: 0.0015994091518223286 | ssim:0.9203352928161621\n",
      "Epoch: 150 || Batch: 109 || unet loss: 0.9632989168167114 || dis loss: 0.2331681251525879 || mse: 0.002036763122305274 | ssim:0.883415937423706\n",
      "Epoch: 150 || Batch: 110 || unet loss: 0.9591970443725586 || dis loss: 0.35395359992980957 || mse: 0.004785588011145592 | ssim:0.8230232000350952\n",
      "Epoch: 150 || Batch: 111 || unet loss: 1.0394136905670166 || dis loss: 0.16091227531433105 || mse: 0.004170137457549572 | ssim:0.9195438623428345\n",
      "Epoch: 150 || Batch: 112 || unet loss: 0.8074866533279419 || dis loss: 0.07784616947174072 || mse: 0.0008919703541323543 | ssim:0.9610769152641296\n",
      "Epoch: 150 || Batch: 113 || unet loss: 0.8254258632659912 || dis loss: 0.12493157386779785 || mse: 0.0011350363492965698 | ssim:0.9375342130661011\n",
      "Epoch: 150 || Batch: 114 || unet loss: 0.9876571893692017 || dis loss: 0.12265551090240479 || mse: 0.00717861857265234 | ssim:0.9386722445487976\n",
      "Epoch: 150 || Batch: 115 || unet loss: 1.0814032554626465 || dis loss: 0.15601658821105957 || mse: 0.0013598850928246975 | ssim:0.9219917058944702\n",
      "Epoch: 150 || Batch: 116 || unet loss: 1.2177953720092773 || dis loss: 0.181793212890625 || mse: 0.001161549356766045 | ssim:0.9091033935546875\n",
      "Epoch: 150 || Batch: 117 || unet loss: 1.0376734733581543 || dis loss: 0.1603156328201294 || mse: 0.001549377804622054 | ssim:0.9198421835899353\n",
      "Epoch: 150 || Batch: 118 || unet loss: 0.8807604312896729 || dis loss: 0.09663116931915283 || mse: 0.0005287477397359908 | ssim:0.9516844153404236\n",
      "Epoch: 150 || Batch: 119 || unet loss: 1.1535025835037231 || dis loss: 0.1470623016357422 || mse: 0.0018081663874909282 | ssim:0.9264688491821289\n",
      "Epoch: 150 || Batch: 120 || unet loss: 1.0981733798980713 || dis loss: 0.15288448333740234 || mse: 0.0015586524968966842 | ssim:0.9235577583312988\n",
      "Epoch: 150 || Batch: 121 || unet loss: 0.9875409007072449 || dis loss: 0.1372966766357422 || mse: 0.0020280424505472183 | ssim:0.9313516616821289\n",
      "Epoch: 150 || Batch: 122 || unet loss: 0.7642300128936768 || dis loss: 0.055222153663635254 || mse: 0.0006331705953925848 | ssim:0.9723889231681824\n",
      "Epoch: 150 || Batch: 123 || unet loss: 0.9274216294288635 || dis loss: 0.07909893989562988 || mse: 0.00145807396620512 | ssim:0.9604505300521851\n",
      "Epoch: 150 || Batch: 124 || unet loss: 0.8661134243011475 || dis loss: 0.09518647193908691 || mse: 0.000754175242036581 | ssim:0.9524067640304565\n",
      "Epoch: 150 || Batch: 125 || unet loss: 1.059178113937378 || dis loss: 0.13442254066467285 || mse: 0.0010501776123419404 | ssim:0.9327887296676636\n",
      "Epoch: 150 || Batch: 126 || unet loss: 0.9345936179161072 || dis loss: 0.14122545719146729 || mse: 0.0008548423065803945 | ssim:0.9293872714042664\n",
      "Epoch: 150 || Batch: 127 || unet loss: 1.1146842241287231 || dis loss: 0.16339612007141113 || mse: 0.006148532032966614 | ssim:0.9183019399642944\n",
      "Epoch: 150 || Batch: 128 || unet loss: 0.781031608581543 || dis loss: 0.0592958927154541 || mse: 0.001658315071836114 | ssim:0.970352053642273\n",
      "Epoch: 150 || Batch: 129 || unet loss: 0.8289759755134583 || dis loss: 0.10104870796203613 || mse: 0.000834947160910815 | ssim:0.9494756460189819\n",
      "Epoch: 150 || Batch: 130 || unet loss: 1.106781005859375 || dis loss: 0.1511554718017578 || mse: 0.0010321165900677443 | ssim:0.9244222640991211\n",
      "Epoch: 150 || Batch: 131 || unet loss: 0.8507698178291321 || dis loss: 0.12084579467773438 || mse: 0.0019529088167473674 | ssim:0.9395771026611328\n",
      "Epoch: 150 || Batch: 132 || unet loss: 0.7606313228607178 || dis loss: 0.05725574493408203 || mse: 0.0002478286041878164 | ssim:0.971372127532959\n",
      "Epoch: 150 || Batch: 133 || unet loss: 1.2064276933670044 || dis loss: 0.19544851779937744 || mse: 0.001649457961320877 | ssim:0.9022757411003113\n",
      "Epoch: 150 || Batch: 134 || unet loss: 1.110216736793518 || dis loss: 0.1627192497253418 || mse: 0.0011132345534861088 | ssim:0.9186403751373291\n",
      "Epoch: 150 || Batch: 135 || unet loss: 0.7642219066619873 || dis loss: 0.05984020233154297 || mse: 0.0006626902613788843 | ssim:0.9700798988342285\n",
      "Epoch: 150 || Batch: 136 || unet loss: 0.9161640405654907 || dis loss: 0.10555136203765869 || mse: 0.0019386726198717952 | ssim:0.9472243189811707\n",
      "Epoch: 150 || Batch: 137 || unet loss: 0.9450843334197998 || dis loss: 0.11698389053344727 || mse: 0.002827124437317252 | ssim:0.9415080547332764\n",
      "Epoch: 150 || Batch: 138 || unet loss: 0.9320372343063354 || dis loss: 0.11705553531646729 || mse: 0.001145929447375238 | ssim:0.9414722323417664\n",
      "Epoch: 150 || Batch: 139 || unet loss: 1.0560636520385742 || dis loss: 0.14021039009094238 || mse: 0.012075573205947876 | ssim:0.9298948049545288\n",
      "Epoch: 150 || Batch: 140 || unet loss: 1.0414695739746094 || dis loss: 0.1436150074005127 || mse: 0.002039654180407524 | ssim:0.9281924962997437\n",
      "Epoch: 150 || Batch: 141 || unet loss: 1.2626932859420776 || dis loss: 0.20509302616119385 || mse: 0.0023163966834545135 | ssim:0.8974534869194031\n",
      "Epoch: 150 || Batch: 142 || unet loss: 1.1452000141143799 || dis loss: 0.19609224796295166 || mse: 0.0012646460672840476 | ssim:0.9019538760185242\n",
      "Epoch: 150 || Batch: 143 || unet loss: 0.8876065015792847 || dis loss: 0.09624254703521729 || mse: 0.000820963061414659 | ssim:0.9518787264823914\n",
      "Epoch: 150 || Batch: 144 || unet loss: 1.1664447784423828 || dis loss: 0.1558837890625 || mse: 0.0020299970638006926 | ssim:0.92205810546875\n",
      "Epoch: 150 || Batch: 145 || unet loss: 1.1434839963912964 || dis loss: 0.16064941883087158 || mse: 0.0013010958209633827 | ssim:0.9196752905845642\n",
      "Epoch: 150 || Batch: 146 || unet loss: 1.1314607858657837 || dis loss: 0.16665852069854736 || mse: 0.0031878924928605556 | ssim:0.9166707396507263\n",
      "Epoch: 150 || Batch: 147 || unet loss: 0.7529195547103882 || dis loss: 0.05513167381286621 || mse: 0.0007519509526900947 | ssim:0.9724341630935669\n",
      "Epoch: 150 || Batch: 148 || unet loss: 0.910606861114502 || dis loss: 0.07427239418029785 || mse: 0.0008261328330263495 | ssim:0.9628638029098511\n",
      "Epoch: 150 || Batch: 149 || unet loss: 0.8587349057197571 || dis loss: 0.09610331058502197 || mse: 0.0006363581633195281 | ssim:0.951948344707489\n",
      "Epoch: 150 || Batch: 150 || unet loss: 1.0985934734344482 || dis loss: 0.15473484992980957 || mse: 0.001608218066394329 | ssim:0.9226325750350952\n",
      "Epoch: 150 || Batch: 151 || unet loss: 0.8163809776306152 || dis loss: 0.12149584293365479 || mse: 0.0009156078449450433 | ssim:0.9392520785331726\n",
      "Epoch: 150 || Batch: 152 || unet loss: 1.093564510345459 || dis loss: 0.4580976963043213 || mse: 0.009061313234269619 | ssim:0.7709511518478394\n",
      "Epoch: 150 || Batch: 153 || unet loss: 0.7942761778831482 || dis loss: 0.06337189674377441 || mse: 0.0011907704174518585 | ssim:0.9683140516281128\n",
      "Epoch: 150 || Batch: 154 || unet loss: 0.8740512132644653 || dis loss: 0.10751080513000488 || mse: 0.0006701271049678326 | ssim:0.9462445974349976\n",
      "Epoch: 150 || Batch: 155 || unet loss: 1.1251685619354248 || dis loss: 0.16389012336730957 || mse: 0.0008068968309089541 | ssim:0.9180549383163452\n",
      "Epoch: 150 || Batch: 156 || unet loss: 0.9261977672576904 || dis loss: 0.1024627685546875 || mse: 0.0004681998398154974 | ssim:0.9487686157226562\n",
      "Epoch: 150 || Batch: 157 || unet loss: 0.7578670382499695 || dis loss: 0.06107807159423828 || mse: 0.00028589877183549106 | ssim:0.9694609642028809\n",
      "Epoch: 150 || Batch: 158 || unet loss: 0.9507894515991211 || dis loss: 0.2937356233596802 || mse: 0.004067517817020416 | ssim:0.8531321883201599\n",
      "Epoch: 150 || Batch: 159 || unet loss: 0.964881181716919 || dis loss: 0.2576003074645996 || mse: 0.0023294587153941393 | ssim:0.8711998462677002\n",
      "Epoch: 150 || Batch: 160 || unet loss: 0.9815067648887634 || dis loss: 0.35719966888427734 || mse: 0.006173084490001202 | ssim:0.8214001655578613\n",
      "Epoch: 150 || Batch: 161 || unet loss: 0.9695441722869873 || dis loss: 0.10504114627838135 || mse: 0.0026934114284813404 | ssim:0.9474794268608093\n",
      "Epoch: 150 || Batch: 162 || unet loss: 0.9226320385932922 || dis loss: 0.11065292358398438 || mse: 0.0017182070296257734 | ssim:0.9446735382080078\n",
      "Epoch: 150 || Batch: 163 || unet loss: 0.9586564302444458 || dis loss: 0.12112951278686523 || mse: 0.0012326467549428344 | ssim:0.9394352436065674\n",
      "Epoch: 150 || Batch: 164 || unet loss: 1.0600894689559937 || dis loss: 0.147369384765625 || mse: 0.009671255946159363 | ssim:0.9263153076171875\n",
      "Epoch: 150 || Batch: 165 || unet loss: 1.2417458295822144 || dis loss: 0.20362210273742676 || mse: 0.001803009188733995 | ssim:0.8981889486312866\n",
      "Epoch: 150 || Batch: 166 || unet loss: 1.3912817239761353 || dis loss: 0.24406838417053223 || mse: 0.0030701677314937115 | ssim:0.8779658079147339\n",
      "Epoch: 150 || Batch: 167 || unet loss: 0.9858075976371765 || dis loss: 0.1433655023574829 || mse: 0.0012391742784529924 | ssim:0.9283172488212585\n",
      "Epoch: 150 || Batch: 168 || unet loss: 0.9197597503662109 || dis loss: 0.1009894609451294 || mse: 0.0006339673418551683 | ssim:0.9495052695274353\n",
      "Epoch: 150 || Batch: 169 || unet loss: 1.1291059255599976 || dis loss: 0.14316177368164062 || mse: 0.0018138338346034288 | ssim:0.9284191131591797\n",
      "Epoch: 150 || Batch: 170 || unet loss: 1.1324806213378906 || dis loss: 0.15158748626708984 || mse: 0.0013444351498037577 | ssim:0.9242062568664551\n",
      "Epoch: 150 || Batch: 171 || unet loss: 1.0354613065719604 || dis loss: 0.15455937385559082 || mse: 0.001700839726254344 | ssim:0.9227203130722046\n",
      "Epoch: 150 || Batch: 172 || unet loss: 0.7792597413063049 || dis loss: 0.060782432556152344 || mse: 0.0004303970781620592 | ssim:0.9696087837219238\n",
      "Epoch: 150 || Batch: 173 || unet loss: 0.7966450452804565 || dis loss: 0.06315898895263672 || mse: 0.0004717470146715641 | ssim:0.9684205055236816\n",
      "Epoch: 150 || Batch: 174 || unet loss: 0.9061968326568604 || dis loss: 0.10991966724395752 || mse: 0.0007648281753063202 | ssim:0.9450401663780212\n",
      "Epoch: 150 || Batch: 175 || unet loss: 1.0495104789733887 || dis loss: 0.13621580600738525 || mse: 0.0011591713409870863 | ssim:0.9318920969963074\n",
      "Epoch: 150 || Batch: 176 || unet loss: 0.8252578377723694 || dis loss: 0.13075947761535645 || mse: 0.0008690031245350838 | ssim:0.9346202611923218\n",
      "Epoch: 150 || Batch: 177 || unet loss: 0.8920164704322815 || dis loss: 0.1542370319366455 || mse: 0.0010250748600810766 | ssim:0.9228814840316772\n",
      "Epoch: 150 || Batch: 178 || unet loss: 0.8260298371315002 || dis loss: 0.07919073104858398 || mse: 0.0012423633597791195 | ssim:0.960404634475708\n",
      "Epoch: 150 || Batch: 179 || unet loss: 0.8524690270423889 || dis loss: 0.19248747825622559 || mse: 0.0020173550583422184 | ssim:0.9037562608718872\n",
      "Epoch: 150 || Batch: 180 || unet loss: 1.030450701713562 || dis loss: 0.12662184238433838 || mse: 0.000807233969680965 | ssim:0.9366890788078308\n",
      "Epoch: 150 || Batch: 181 || unet loss: 0.9163705110549927 || dis loss: 0.09793710708618164 || mse: 0.0004657762765418738 | ssim:0.9510314464569092\n",
      "Epoch: 150 || Batch: 182 || unet loss: 0.7428677082061768 || dis loss: 0.056488633155822754 || mse: 0.0002214759006164968 | ssim:0.9717556834220886\n",
      "Epoch: 150 || Batch: 183 || unet loss: 1.222504734992981 || dis loss: 0.19682931900024414 || mse: 0.0016232188791036606 | ssim:0.9015853404998779\n",
      "Epoch: 150 || Batch: 184 || unet loss: 0.9457616806030273 || dis loss: 0.201951265335083 || mse: 0.0018973944243043661 | ssim:0.8990243673324585\n",
      "Epoch: 150 || Batch: 185 || unet loss: 0.919121503829956 || dis loss: 0.30780696868896484 || mse: 0.004484986886382103 | ssim:0.8460965156555176\n",
      "Epoch: 150 || Batch: 186 || unet loss: 1.0333502292633057 || dis loss: 0.13888561725616455 || mse: 0.0022079860791563988 | ssim:0.9305571913719177\n",
      "Epoch: 150 || Batch: 187 || unet loss: 0.8621681928634644 || dis loss: 0.08765506744384766 || mse: 0.0009216981707140803 | ssim:0.9561724662780762\n",
      "Epoch: 150 || Batch: 188 || unet loss: 0.9446682929992676 || dis loss: 0.11973834037780762 || mse: 0.0012394699733704329 | ssim:0.9401308298110962\n",
      "Epoch: 150 || Batch: 189 || unet loss: 1.0226573944091797 || dis loss: 0.13836908340454102 || mse: 0.007233684416860342 | ssim:0.9308154582977295\n",
      "Epoch: 150 || Batch: 190 || unet loss: 1.0308376550674438 || dis loss: 0.1439526081085205 || mse: 0.002407858381047845 | ssim:0.9280236959457397\n",
      "Epoch: 150 || Batch: 191 || unet loss: 1.2956523895263672 || dis loss: 0.21178698539733887 || mse: 0.0016982568195089698 | ssim:0.8941065073013306\n",
      "Epoch: 150 || Batch: 192 || unet loss: 0.8531294465065002 || dis loss: 0.10578262805938721 || mse: 0.0009713565814308822 | ssim:0.9471086859703064\n",
      "Epoch: 150 || Batch: 193 || unet loss: 0.8328995704650879 || dis loss: 0.08594954013824463 || mse: 0.0011927896412089467 | ssim:0.9570252299308777\n",
      "Epoch: 150 || Batch: 194 || unet loss: 1.162085771560669 || dis loss: 0.15559256076812744 || mse: 0.0021845772862434387 | ssim:0.9222037196159363\n",
      "Epoch: 150 || Batch: 195 || unet loss: 0.9874172210693359 || dis loss: 0.12428879737854004 || mse: 0.0016075714956969023 | ssim:0.93785560131073\n",
      "Epoch: 150 || Batch: 196 || unet loss: 0.9899190664291382 || dis loss: 0.13483190536499023 || mse: 0.0021698283962905407 | ssim:0.9325840473175049\n",
      "Epoch: 150 || Batch: 197 || unet loss: 0.7604396939277649 || dis loss: 0.05486702919006348 || mse: 0.0005888855666853487 | ssim:0.9725664854049683\n",
      "Epoch: 150 || Batch: 198 || unet loss: 0.7890788316726685 || dis loss: 0.09997177124023438 || mse: 0.000761489849537611 | ssim:0.9500141143798828\n",
      "Epoch: 150 || Batch: 199 || unet loss: 0.8930759429931641 || dis loss: 0.10352325439453125 || mse: 0.0007825574139133096 | ssim:0.9482383728027344\n",
      "Epoch: 150 || Batch: 200 || unet loss: 1.0489134788513184 || dis loss: 0.1390979290008545 || mse: 0.0013165452983230352 | ssim:0.9304510354995728\n",
      "Epoch: 150 || Batch: 201 || unet loss: 0.9532866477966309 || dis loss: 0.14382100105285645 || mse: 0.0031219846569001675 | ssim:0.9280894994735718\n",
      "Epoch: 150 || Batch: 202 || unet loss: 1.1060614585876465 || dis loss: 0.15837907791137695 || mse: 0.009044271893799305 | ssim:0.9208104610443115\n",
      "Epoch: 150 || Batch: 203 || unet loss: 0.800295889377594 || dis loss: 0.07181668281555176 || mse: 0.0013315588003024459 | ssim:0.9640916585922241\n",
      "Epoch: 150 || Batch: 204 || unet loss: 0.7913296222686768 || dis loss: 0.08234226703643799 || mse: 0.0006885186303406954 | ssim:0.958828866481781\n",
      "Epoch: 150 || Batch: 205 || unet loss: 1.1208750009536743 || dis loss: 0.16451144218444824 || mse: 0.0007175765349529684 | ssim:0.9177442789077759\n",
      "Epoch: 150 || Batch: 206 || unet loss: 0.9887418746948242 || dis loss: 0.11076927185058594 || mse: 0.0007629047031514347 | ssim:0.944615364074707\n",
      "Epoch: 150 || Batch: 207 || unet loss: 0.8277525901794434 || dis loss: 0.07197690010070801 || mse: 0.000655891839414835 | ssim:0.964011549949646\n",
      "Epoch: 150 || Batch: 208 || unet loss: 1.176018238067627 || dis loss: 0.18073272705078125 || mse: 0.0013743153540417552 | ssim:0.9096336364746094\n",
      "Epoch: 150 || Batch: 209 || unet loss: 1.067480444908142 || dis loss: 0.1706526279449463 || mse: 0.001242862781509757 | ssim:0.9146736860275269\n",
      "Epoch: 150 || Batch: 210 || unet loss: 0.7436355352401733 || dis loss: 0.06429314613342285 || mse: 0.0010444556828588247 | ssim:0.9678534269332886\n",
      "\n",
      "mse: + 0.001793582907848069 | ssim: 0.9273317772630266 | unet:0.9623633433857235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "train(epochs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vXFZE36R-C_"
   },
   "source": [
    "Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKT5tEJmAABT"
   },
   "outputs": [],
   "source": [
    "path_of_generator_weight = 'weight/generator.pth'  #path for storing the weights of genertaor\n",
    "path_of_discriminator_weight = 'weight/discriminator.pth'  #path for storing the weights of discriminator\n",
    "DUNet.save_weight(path_of_generator_weight,path_of_discriminator_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWqkb8epSIup"
   },
   "source": [
    "Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPjwtGKeAABV"
   },
   "outputs": [],
   "source": [
    "path_of_generator_weight = 'weight/generator.pth'  #path where the weights of genertaor are stored\n",
    "path_of_discriminator_weight = 'weight/discriminator.pth'  #path where the weights of discriminator are stored\n",
    "DUNet.load('weights/new/in all/u_' + str(21) + '.pth','weights/new/in all/d_' + str(21) + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MAztif9SRC_"
   },
   "source": [
    "Runing the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEMIiCj3AABe"
   },
   "outputs": [],
   "source": [
    "def to_tensor(img):\n",
    "    img_t = F6.to_tensor(img).float()\n",
    "    return img_t\n",
    "\n",
    "def postprocess(img):\n",
    "        img = img * 255.0\n",
    "        img = img.permute(0, 2, 3, 1)\n",
    "        return img.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bb-OyJTAABh"
   },
   "outputs": [],
   "source": [
    "path_of_test_hazy_images = 'test/haze/*.png'\n",
    "path_for_resultant_dehaze_images = 'test/result/'\n",
    "image_paths_test_hazy=glob.glob(path_of_test_hazy_images)\n",
    "\n",
    "for i in range(len(image_paths_test_hazy)):\n",
    "    haze_image = cv2.imread(image_paths_test_hazy[i])\n",
    "    haze_image = PIL.Image.fromarray(haze_image)\n",
    "    haze_image = haze_image.resize((512,512), resample=PIL.Image.BICUBIC)\n",
    "    haze_image = np.array(haze_image)\n",
    "    haze_image = cv2.cvtColor(haze_image, cv2.COLOR_BGR2YCrCb)\n",
    "    haze_image = to_tensor(haze_image).cuda()\n",
    "    haze_image = haze_image.reshape(1,3,512,512)\n",
    "\n",
    "    dehaze_image = DUNet.predict(haze_image) \n",
    "    \n",
    "    dehaze_image = postprocess(dehaze_image)[0]\n",
    "    dehaze_image = dehaze_image.cpu().detach().numpy()\n",
    "    dehaze_image = dehaze_image.astype('uint8')\n",
    "    dehaze_image = dehaze_image.reshape(512,512,3)\n",
    "    dehaze_image = cv2.cvtColor(dehaze_image, cv2.COLOR_YCrCb2BGR)\n",
    "    cv2.imwrite(path_for_resultant_dehaze_images+str(i+50)+'.png', dehaze_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcYTCrl_SZGz"
   },
   "source": [
    "Calculating the metrices i.e PSNR and SSIM for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgJC-JMuAABl"
   },
   "outputs": [],
   "source": [
    "class EdgeAccuracy(nn.Module):\n",
    "    \"\"\"\n",
    "    Measures the accuracy of the edge map\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, inputs, outputs):\n",
    "        labels = (inputs > self.threshold)\n",
    "        outputs = (outputs > self.threshold)\n",
    "\n",
    "        relevant = torch.sum(labels.float())\n",
    "        selected = torch.sum(outputs.float())\n",
    "\n",
    "        if relevant == 0 and selected == 0:\n",
    "            return 1, 1\n",
    "\n",
    "        true_positive = ((outputs == labels) * labels).float()\n",
    "        recall = torch.sum(true_positive) / (relevant + 1e-8)\n",
    "        precision = torch.sum(true_positive) / (selected + 1e-8)\n",
    "\n",
    "        return precision, recall\n",
    "\n",
    "\n",
    "class PSNR(nn.Module):\n",
    "    def __init__(self, max_val=0):\n",
    "        super().__init__()\n",
    "\n",
    "        base10 = torch.log(torch.tensor(10.0))\n",
    "        max_val = torch.tensor(max_val).float()\n",
    "\n",
    "        self.register_buffer('base10', base10)\n",
    "        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n",
    "\n",
    "    def __call__(self, a, b):\n",
    "        mse = torch.mean((a.float() - b.float()) ** 2)\n",
    "    \n",
    "        if mse == 0:\n",
    "            return 0\n",
    "\n",
    "        return 1.0 / mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fsxd9gSxAABm"
   },
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F9.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F9.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F9.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F9.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F9.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hTzS1wUAABq"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'image_paths_GT' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5abc67defc4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths_test_hazy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths_GT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_paths_GT' is not defined"
     ]
    }
   ],
   "source": [
    "ssim = SSIM(window_size = 11)\n",
    "psnr = PSNR()\n",
    "psnr_val = 0\n",
    "psnr_val = 0.0\n",
    "final_ssim = 0\n",
    "\n",
    "path_of_test_hazy_images = 'test/haze/*.png'\n",
    "path_of_test_gt_images = 'test/gt/*.png'\n",
    "path_for_resultant_dehaze_images = 'test/result/'\n",
    "\n",
    "image_paths_test_hazy=glob.glob(path_of_test_hazy_images)\n",
    "image_paths_test_gt=glob.glob(path_of_test_gt_images)\n",
    "image_paths_result=glob.glob(path_for_resultant_dehaze_images)\n",
    "\n",
    "for i in range(len(image_paths_test_hazy)):\n",
    "    im1 = cv2.imread(image_paths_result[i])\n",
    "    im1 = Image.fromarray(im1)\n",
    "    im1 = im1.resize((512,512), resample=PIL.Image.BICUBIC)\n",
    "    im1 = np.array(im1)\n",
    "    im2 = cv2.imread('Results/experiment yrcrcb/new/outdoor/' + str(i+50)+'.png')\n",
    "\n",
    "    im1 = to_tensor(im1).reshape(1,3,512,512)\n",
    "    im2 = to_tensor(im2).reshape(1,3,512,512)\n",
    "    \n",
    "    psnr_val = psnr(im1, im2)\n",
    "    final_psnr = final_psnr + 10*np.log10((psnr_val))\n",
    "    final_ssim = final_ssim + ssim(im1, im2)\n",
    "\n",
    "\n",
    "print(final_ssim/5.0, final_psnr/5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGWLUya4AAB0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Single Image Dehazing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pythonjvsc74a57bd0d3b223a96a5f7facd6d4bd41a0efd00e5c868cc1263596eeeb7cdb49f40ea1f3",
   "display_name": "Python 3.9.4  ('windows_env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "d3b223a96a5f7facd6d4bd41a0efd00e5c868cc1263596eeeb7cdb49f40ea1f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}